---
title: "TP6 - Modelos lineales"
author: "Spiousas - Etchemendy"
date: "`r Sys.Date()`"
output: 
  rmdformats::robobook
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  echo = TRUE, 
  eval = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>"
)

library(RCurl)
```

En este trabajo vamos a poner en práctica los conceptos aprendidos sobre regresión lineal, regresión múltiple e inferencia.


```{r}
# install.packages("tidyverse")
library(tidyverse)
```

## 1 - Regresión lineal 

Utilizando el dataset `starbucks` del paquete *{openintro}*, ajuste un modelo lineal para estimar las calorías de un producto `calories` utilizando como predictor los gramos de grasa `fat`.

Visualice los resultados y escribir la ecuación del modelo.

Visualice los residuos.

Estime las calorías de un nuevo producto con **19 gramos de grasa**.

¿Qué pasa cuando hay 0 gramos de grasa?

¿Cómo varía la pendiente si ajustamos el mismo modelos pero utilizando `carb`, `fiber` o `protein`?

Volvamos al modelo con `fat`. si vemos la salida de `summary()`, ¿Qué puede decir del $R^2$ y del $p$?

Agreguede a uno cada uno de estos outliers y estude cómo afectan a la pendiente. 

- Outlier 1: `fat=25, calories=150`
- Outlier 2: `fat=50, calories=150`
- Outlier 3: `fat=50, calories=700`

```{r}
# Ajuste
library(openintro)
model_starbucks <- starbucks %>% 
  lm(calories ~ fat, .)
model_starbucks

starbucks %>% ggplot(aes(x = fat,
                         y = calories)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE)

# Residuos
cbind(starbucks, resid(model_starbucks)) %>%
  rename("residuals" = "resid(model_starbucks)") %>%
  ggplot(aes(x = fat,
             y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color= "#ED6A5A", linetype = "dashed")
         
# Prediccion               
predict.lm(model_starbucks, tibble(fat = 19))                         
predict.lm(model_starbucks, tibble(fat = 0))

# Modelos alternativos
model_starbucks_carb <- starbucks %>% 
  lm(calories ~ carb, .)
model_starbucks_carb

model_starbucks_protein <- starbucks %>% 
  lm(calories ~ protein, .)
model_starbucks_protein

model_starbucks_fiber <- starbucks %>% 
  lm(calories ~ fiber, .)
model_starbucks_fiber

# Summary
summary(model_starbucks)

# Outliers
starbucks_out1 <- starbucks %>%
  dplyr::select(c("calories", "fat")) %>%
  rbind(tibble(fat = 25, calories = 150))

starbucks_out1 %>%
  ggplot(aes(x = fat,
             y = calories)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE)
  
model_starbucks_out1 <- starbucks_out1 %>% 
  lm(calories ~ fat, .)
model_starbucks_out1

starbucks_out2 <- starbucks %>%
  dplyr::select(c("calories", "fat")) %>%
  rbind(tibble(fat = 50, calories = 150))

starbucks_out2 %>%
  ggplot(aes(x = fat,
             y = calories)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE)
  
model_starbucks_out2 <- starbucks_out2 %>% 
  lm(calories ~ fat, .)
model_starbucks_out2

starbucks_out3 <- starbucks %>%
  dplyr::select(c("calories", "fat")) %>%
  rbind(tibble(fat = 50, calories = 700))

starbucks_out3 %>%
  ggplot(aes(x = fat,
             y = calories)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE)
  
model_starbucks_out3 <- starbucks_out3 %>% 
  lm(calories ~ fat, .)
model_starbucks_out3
```
## 2 - Regesión multiple

Utilizando el dataset `penguins`del paquete *{palmerpenguins}*, ajuste un modelo lineal para estimar el peso de los pinguinos (en g) `body_mass_g` a partir de la variable continua ancho de pico (en mm) `bill_depth_mm` y la variable discreta especie `species`,sin interacción.

Escriba la ecuación y estime el peso de un pinguino **Chinstrap** de ancho de pico **18 mm**.

Más allá de los parámetros ¿Qué puede decir del efecto conjunto de la variable discreta `species`?

Agerguemos la interacción al modelo ¿Es significativamente más "explicativo"? Volvamos a escribir la ecuación y a estimar el peso para un pinguino **Chinstrap** de ancho de pico **18 mm**.

```{r}
library(palmerpenguins)

# Modelo 
model_penguins <- penguins %>%
  drop_na() %>%
  lm(body_mass_g ~ bill_depth_mm + species, .)

summary(model_penguins)

predict.lm(model_penguins, tibble(bill_depth_mm = 18, species = "Chinstrap"))

# Peso = -1000.846 + 256.551 * bill_depth_mm + 8.111 * speciesChinstrap + 2245.878 * speciesGentoo

library(car)
Anova(model_penguins, type = 3)

# Modelo con interacción
model_penguins_interaction <- penguins %>%
  drop_na() %>%
  lm(body_mass_g ~ bill_depth_mm * species, .)

summary(model_penguins_interaction)

# Comparación de modelos
anova(model_penguins, model_penguins_interaction)

# Nueva ecuación y predicción
# Peso = -297.38 + 218.21 * bill_depth_mm + 261.16 * speciesChinstrap - 124.43 * speciesGentoo - 13.58 * bill_depth_mm X speciesChinstrap + 149.49 *bill_depth_mm X speciesGentoo

predict.lm(model_penguins_interaction, tibble(bill_depth_mm = 18, species = "Chinstrap"))
```
## 3 - Intervalos de confianza
Utilizando la siguiente ecuación: 

$$ Peso = 500 + 1 \times Dientes $$
Genere una muestra de 2000 datos de la siguiente forma:

```{r, echo=TRUE}
set.seed(4)
data_dientes <- tibble(Dientes = round(rnorm(2000) * 10+50),
                       Peso = (500 +  1 * Dientes) + rnorm(2000) * 30)
```

tome 200 muestras aleatorias de 20 individuos y calcule cuántas veces el valor real de la pendiente es contenido por el intervalo de confianza.

¿Qué pasa si en lugar de ser muestras de 20 individuos son de 50?

```{r}
# Modelo con la muestra
model_dientes <- data_dientes %>%
  lm(Peso ~ Dientes, .)

library(parameters)
model_parameters(model_dientes)

# 200 realizaciones d eun experimento tomando 20 datos
set.seed(4)
CI_in <- tibble(index = 1:200,
                low = 0,
                high = 0,
                isin = FALSE)
for (i in 1:200) {
  data_sample <- data_dientes %>% sample_n(size = 20)  
  model_sample <- lm(Peso ~ Dientes, data_sample)
  CI_in$low[i] <- model_parameters(model_sample)$CI_low[2]
  CI_in$high[i] <- model_parameters(model_sample)$CI_high[2]
  CI_in$isin[i] <- between(1, model_parameters(model_sample)$CI_low[2], model_parameters(model_sample)$CI_high[2])
  print(paste0(i, " low:", CI_in$low[i], " high:", CI_in$high[i], "IN:", CI_in$isin[i]))
}
# Porcentaje de esos experimentos en los que el CI contiene a 1
sum(CI_in$isin)/200*100

# 200 realizaciones d eun experimento tomando 50 datos
set.seed(14)
CI_in_50 <- tibble(index = 1:200,
                low = 0,
                high = 0,
                isin = FALSE)
for (i in 1:200) {
  data_sample <- data_dientes %>% sample_n(size = 50)  
  model_sample <- lm(Peso ~ Dientes, data_sample)
  CI_in_50$low[i] <- model_parameters(model_sample)$CI_low[2]
  CI_in_50$high[i] <- model_parameters(model_sample)$CI_high[2]
  CI_in_50$isin[i] <- between(1, model_parameters(model_sample)$CI_low[2], model_parameters(model_sample)$CI_high[2])
  print(paste0(i, " low:", CI_in_50$low[i], " high:", CI_in_50$high[i], "IN:", CI_in_50$isin[i]))
}
# Porcentaje de esos experimentos en los que el CI contiene a 1
sum(CI_in_50$isin)/200*100

# Evolución del ancho de los CIs
ggplot() +
  geom_ribbon(data = CI_in, aes(x = index, ymin = low, ymax = high), fill = "#1380A1", alpha = 0.6) + 
  geom_ribbon(data = CI_in_50, aes(x = index, ymin = low, ymax = high), fill = "#ED6A5A", alpha = 0.6) +
  geom_hline(yintercept = 1, color = "black", linetype = "dashed")
  
```

## 4 - La interacción

Utilizando el dataset `cats` del paquete *{MASS}*, ajuste un modelo lineal para estimar el peso del corazón (en g) `Hwt` a partir de la variable continua peso del cuerpo (en Kg) `Bwt` y la variable discreta sexo `Sex`.

Vizualice los resultados e interprete la salida de `summary()` ¿Hay diferencia entre `summary()` y `Anova(. , type =3)`? ¿Por qué?

Escriba la ecuación y estime el peso del corazón para un gato **macho** de **3 Kg** y para una gata **hembra** de **2 Kg**.

Escribe el modelo lineal para gatos hembras y machos agrupando pendientes y ordenadas al origen ¿Para qué sexo la pendiente es más empinada?

```{r}
# install.packages("MASS")
library(MASS)

# Modelo gatos
model_cats <- cats %>% lm(Hwt ~ Bwt * Sex, .)
summary(model_cats)
Anova(model_cats, type = 3)
# PesoCora = 2.9813 + 2.6364 * PesoTotal - 4.1654 * SexoM + 1.6763 * PesoTotal x SexoM
# Gato hembra:
# PesoCoraH = 2.9813 + 2.6364 * PesoTotal
# Gato macho:
# PesoCoraM = (2.9813 - 4.1654) + (2.6364 + 1.6763) * PesoTotal
```

## 5 - Muchas variables

Utilizando el dataset `birth14` del paquete *{openintro}*, ajuste un modelo lineal para estimar el peso de los recién nacidos (en libras) `weight` utilizando como regresores la longitud del embarazo en semanas `weeks`, la edad de la madre en años `mage`, el sexo del bebé `sex`, si la madre era fumadora `habit`, y el número de visitas al hospital durante el embarazo `visits`.

Escriba la ecuación del modelo completo.

Interprete las pendientes de `weeks` y `habit` en este contexo.

Calcule los residuos para el primer valor del dataset.

Estime el peso **en Kg** para un bebé *female* nacido después de **39 semanas** de embarazo, con una madre de **38 años** de edad, **fumadora** y con **12 visitas** al hospital durante el embarazo.

```{r}
# El modelo
library(openintro)

model_births <- births14 %>% 
  drop_na() %>% 
  lm(weight ~ weeks + mage + sex + habit + visits, .) 

summary(model_births)

# Peso = -3.650658 + 0.263989 * weeks + 0.014886 * mage + 0.424400 * sexmale - 0.449862 habitsmoker + 0.006442 * visits

# Residuos
residuo <- abs(predict.lm(model_births, births14[1,]) - births14$weight[1])

# Predicciones
predict.lm(model_births, tibble(sex = "female", weeks = 39, mage = 38, habit = "smoker", visits = 12)) * 0.453592
```